{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFQ_Example_MetaLearning_QAOA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2azAL4KJk-T",
        "colab_type": "text"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Quantum Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UFpHoRvJmwd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BswWgdtnmSP",
        "colab_type": "text"
      },
      "source": [
        "# Meta-Learning for QAOA\n",
        "\n",
        "In this notebook you will explore the application of meta-learning techniques from [here](https://arxiv.org/abs/1907.05415) to improve initialization of QAOA.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTb-AuXh1OY2",
        "colab_type": "text"
      },
      "source": [
        "Authors : Michael Broughton, Antonio J. Martinez\n",
        "\n",
        "Contributors: Guillaume Verdon\n",
        "\n",
        "Created : 2020-Feb-06\n",
        "\n",
        "Last updated : 2020-Apr-09"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MH1spy1rJ2ko",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/quantum/blob/research/metalearning_qaoa/metalearning_qaoa.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrWw_xv4fs44",
        "colab_type": "text"
      },
      "source": [
        "## Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuXxC5fbaGAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade tensorflow==2.3.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyrqkto1aHQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-quantum"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW2sb1rAfhwt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cirq\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import random\n",
        "import sympy\n",
        "import tensorflow as tf\n",
        "import tensorflow_quantum as tfq\n",
        "np.random.seed(123)\n",
        "random.seed(123)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0rC9eTXqPaR",
        "colab_type": "text"
      },
      "source": [
        "## QAOA\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JywerwWEqsqY",
        "colab_type": "text"
      },
      "source": [
        "The QAOA ansatz consists of repeated applications of a mixer Hamiltonian $\\hat{H}_M$ and the cost Hamiltonian $\\hat{H}_C$.  The total applied unitary is\n",
        "$$\\hat{U}(\\eta,\\gamma) = \\prod_{j=1}^{p}e^{-i\\eta_{j}\\hat{H}_M}e^{-i\\gamma_{j} \\hat{H}_C},$$\n",
        "where $p$ is the number of times the mixer and cost are applied; the parameters $\\eta_j, \\gamma_j$ are to be optimized to produce a bitstring of minimal energy with respect to $\\hat{H}_C$.\n",
        "\n",
        "One traditional family of Hamiltonians used in QAOA are the Ising models.  These are defined as\n",
        "$$\\hat{H}_\\mathrm{P}=\\sum_i h_i \\hat{Z}^{(i)}+\\sum_{i,j} J_{ij} \\hat{Z}^{(i)}\\hat{Z}^{(j)}.$$\n",
        "There is a one-to-one mapping between weighted graphs and Ising models: $h_i$ can be thought of as the weight of a graph node $i$ and $J_{ij}$ can be thought of as the weight of a graph edge between nodes $i$ and $j$.  In applications such as [MaxCut](https://en.wikipedia.org/wiki/Maximum_cut), we have $h_i = 0$ and $J_{ij} = 1$ for all indices $i$ and $j$.  The importance of this graph correspondence motivates us to define the following function, which takes a graph and returns the corresponding Ising model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsYSfSCrqVMp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def maxcut_qaoa_from_graph(graph, p):\n",
        "  qubits = cirq.GridQubit.rect(1, len(graph.nodes))\n",
        "  qaoa_circuit = cirq.Circuit()\n",
        "  # Initial equal superposition\n",
        "  for qubit in qubits:\n",
        "    qaoa_circuit += cirq.H(qubit)\n",
        "  qaoa_symbols = []\n",
        "  # Stack the parameterized costs and mixers\n",
        "  for l_num in range(p):\n",
        "    qaoa_symbols.append(sympy.Symbol(\"gamma_{}\".format(l_num)))\n",
        "    for e in graph.edges():\n",
        "      qaoa_circuit += cirq.ZZ(qubits[e[0]], qubits[e[1]])**qaoa_symbols[-1]\n",
        "    qaoa_symbols.append(sympy.Symbol(\"eta_{}\".format(l_num)))\n",
        "    for n in graph.nodes():\n",
        "      qaoa_circuit += cirq.X(qubits[n])**qaoa_symbols[-1]\n",
        "  # Define the cost as a Cirq PauliSum\n",
        "  cost_op = None\n",
        "  for e in graph.edges():\n",
        "    if cost_op is None:\n",
        "      cost_op = cirq.Z(qubits[e[0]])*cirq.Z(qubits[e[1]])\n",
        "    else:\n",
        "      cost_op += cirq.Z(qubits[e[0]])*cirq.Z(qubits[e[1]])\n",
        "  return qaoa_circuit, qaoa_symbols, cost_op"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qsBNoLYr3M4",
        "colab_type": "text"
      },
      "source": [
        "## Meta-Learning for MaxCut"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbUFDaCtgc78",
        "colab_type": "text"
      },
      "source": [
        "The idea of meta-learning for optimization is to train an outer-loop optimizer on many instances of a problem class, to enhance the efficiency of solving unseen instances.  In other words, the learner is attempting to extract the common structure among instances of a particular class of problems.\n",
        "\n",
        "Here, you will use a recurrent neural network to find good initial parameter settings for MaxCut QAOA instances.  As shown in the [original paper](https://arxiv.org/abs/1907.05415), this is an effective method for overcoming the challenge of [\"barren plateaus\"](https://www.nature.com/articles/s41467-018-07090-4) in quantum machine learning.\n",
        "\n",
        "To this end we define a function that generates a set of random MaxCut QAOA instances, based on graphs sampled from an [Erdős–Rényi](https://en.wikipedia.org/wiki/Erd%C5%91s%E2%80%93R%C3%A9nyi_model) distribution:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2iWPCuIf1DZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_data(n_nodes, n_points):\n",
        "  datapoints = []\n",
        "  costs = []\n",
        "  for _ in range(n_points):\n",
        "    random_graph = nx.gnp_random_graph(n_nodes, p=3. / n_nodes)\n",
        "    circuit, symbols, cost_op = maxcut_qaoa_from_graph(random_graph, 1)\n",
        "    datapoints.append(circuit)\n",
        "    costs.append([cost_op])\n",
        "  return datapoints, symbols, costs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqp69jRYgqUy",
        "colab_type": "text"
      },
      "source": [
        "Since our recurrent neural network will have both classical and quantum components, we will need to define a custom RNN layer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ufim5zxtK5n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class QRNN(tf.keras.layers.Layer):\n",
        "  def __init__(self, symbol_names):\n",
        "    super(QRNN, self).__init__()\n",
        "    self.shared = tf.keras.layers.Dense(25, name=\"shared\")\n",
        "    self.state = tf.keras.layers.Dense(25, name=\"state\")\n",
        "    self.params = tf.keras.layers.Dense(2, name=\"params\")\n",
        "    self.expectation = tfq.layers.Expectation()\n",
        "    self.symbol_names = symbol_names\n",
        "\n",
        "  def call(self, inputs):\n",
        "    circuits = inputs[0]\n",
        "    ops = inputs[1]\n",
        "    state = inputs[2]\n",
        "    params = inputs[3]\n",
        "    prev_output = inputs[4]\n",
        "    joined = tf.keras.layers.concatenate([state, params, prev_output])\n",
        "    shared = self.shared(joined)\n",
        "    s_inp = self.state(shared)\n",
        "    p_inp = self.params(shared)\n",
        "    exp_out = self.expectation(circuits,\n",
        "                               symbol_names=self.symbol_names,\n",
        "                               symbol_values=p_inp,\n",
        "                               operators=ops)\n",
        "    return [circuits, ops, s_inp, p_inp, exp_out]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4XJuhHfw8ZA",
        "colab_type": "text"
      },
      "source": [
        "This layer is stacked to produce the meta-learner RNN.  We choose 5 shots of optimization:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPL-CRJUgj_X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate random MaxCut instances as training data.\n",
        "N_QUBITS = 10\n",
        "\n",
        "# For a more accurate optimizer on testing data, increase N_POINTS\n",
        "N_POINTS = 500\n",
        "circuits, symbols, ops = generate_data(N_QUBITS, N_POINTS)\n",
        "circuit_tensor = tfq.convert_to_tensor(circuits)\n",
        "ops_tensor = tfq.convert_to_tensor(ops)\n",
        "\n",
        "# Unroll the RNN through time.\n",
        "state_inp = tf.keras.Input(shape=(25,))\n",
        "params_inp = tf.keras.Input(shape=(2,))\n",
        "exp_inp = tf.keras.Input(shape=(25,))\n",
        "\n",
        "op_inp = tf.keras.Input(shape=(1,), dtype=tf.dtypes.string)\n",
        "circuit_inp = tf.keras.Input(shape=(), dtype=tf.dtypes.string)\n",
        "\n",
        "rnn_0 = QRNN(symbols)\n",
        "rnn_1 = QRNN(symbols)\n",
        "rnn_2 = QRNN(symbols)\n",
        "rnn_3 = QRNN(symbols)\n",
        "rnn_4 = QRNN(symbols)\n",
        "output_0 = rnn_0([circuit_inp, op_inp, state_inp, params_inp, exp_inp])\n",
        "output_1 = rnn_1(output_0)\n",
        "output_2 = rnn_2(output_1)\n",
        "output_3 = rnn_3(output_2)\n",
        "output_4 = rnn_4(output_3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCmvJEUrGsXs",
        "colab_type": "text"
      },
      "source": [
        "Now we can set up a loss function over the 5 timesteps of our RNN QAOA optimizer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7Fp2eOYzsAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def value_loss(unused, outputs):\n",
        "    return tf.reduce_mean(outputs)\n",
        "\n",
        "# It's important to have a good guess on the last shot of the optimization\n",
        "loss = tf.keras.layers.average([\n",
        "    0.1 * output_0[4], 0.2 * output_1[4], 0.3 * output_2[4],\n",
        "    0.4 * output_3[4], 0.5 * output_4[4]\n",
        "])\n",
        "\n",
        "# Penalize jumping around randomly in the landscape.\n",
        "penalizer = 10 * tf.reduce_sum(\n",
        "    (output_0[3] - output_1[3])**2 + (output_1[3] - output_2[3])**2 +\n",
        "    (output_2[3] - output_3[3])**2 + (output_3[3] - output_4[3])**2,\n",
        "    axis=1)\n",
        "full_loss = loss + penalizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UM-UGe11UPXp",
        "colab_type": "text"
      },
      "source": [
        "Finally we set and train our full Keras model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sykuyNseURcC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Can change these to random along with longer tine horizon and greater training\n",
        "# data for more robust test set performance\n",
        "initial_state = np.zeros((N_POINTS, 25)).astype(np.float32)\n",
        "initial_params = np.zeros((N_POINTS, 2)).astype(np.float32)\n",
        "initial_exp = np.zeros((N_POINTS, 25)).astype(np.float32)\n",
        "\n",
        "# Our model will output it's parameter guesses along with the loss value that is\n",
        "# computed over them. This way we can use the model to guess parameters later on\n",
        "model = tf.keras.Model(inputs=[circuit_inp, op_inp, state_inp, params_inp, exp_inp],\n",
        "    outputs=[\n",
        "        output_0[3], output_1[3], output_2[3], output_3[3], output_4[3],\n",
        "        full_loss\n",
        "    ])\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "              loss=value_loss, loss_weights=[0, 0, 0, 0, 0, 1])\n",
        "\n",
        "model.fit(x=[circuit_tensor, ops_tensor, initial_state, initial_params, initial_exp],\n",
        "          y=[\n",
        "              np.zeros((N_POINTS, 1)),\n",
        "              np.zeros((N_POINTS, 1)),\n",
        "              np.zeros((N_POINTS, 1)),\n",
        "              np.zeros((N_POINTS, 1)),\n",
        "              np.zeros((N_POINTS, 1)),\n",
        "              np.zeros((N_POINTS, 1))\n",
        "          ],\n",
        "          epochs=20,\n",
        "          batch_size=64,\n",
        "          verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYxwwKM3g4vL",
        "colab_type": "text"
      },
      "source": [
        "(Doing validation data.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptNh_hPig1zk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "circuits, parameters, ops = generate_data(10, N_POINTS // 2)\n",
        "\n",
        "circuit_tensor = tfq.convert_to_tensor(circuits)\n",
        "ops_tensor = tfq.convert_to_tensor(ops)\n",
        "\n",
        "initial_state = np.zeros((N_POINTS // 2, 25)).astype(np.float32)\n",
        "initial_guesses = np.zeros((N_POINTS // 2, 2)).astype(np.float32)\n",
        "initial_exp = np.zeros((N_POINTS // 2, 25)).astype(np.float32)\n",
        "\n",
        "out1, out2, out3, out4, out5, _ = model(\n",
        "    [circuit_tensor, ops_tensor, initial_state, initial_guesses, initial_exp])\n",
        "\n",
        "one_vals = tf.reduce_mean(tfq.layers.Expectation()(\n",
        "    circuit_tensor,\n",
        "    symbol_names=parameters,\n",
        "    symbol_values=out1,\n",
        "    operators=ops_tensor)).numpy()\n",
        "two_vals = tf.reduce_mean(tfq.layers.Expectation()(\n",
        "    circuit_tensor,\n",
        "    symbol_names=parameters,\n",
        "    symbol_values=out2,\n",
        "    operators=ops_tensor)).numpy()\n",
        "three_vals = tf.reduce_mean(tfq.layers.Expectation()(\n",
        "    circuit_tensor,\n",
        "    symbol_names=parameters,\n",
        "    symbol_values=out3,\n",
        "    operators=ops_tensor)).numpy()\n",
        "four_vals = tf.reduce_mean(tfq.layers.Expectation()(\n",
        "    circuit_tensor,\n",
        "    symbol_names=parameters,\n",
        "    symbol_values=out4,\n",
        "    operators=ops_tensor)).numpy()\n",
        "five_vals = tf.reduce_mean(tfq.layers.Expectation()(\n",
        "    circuit_tensor,\n",
        "    symbol_names=parameters,\n",
        "    symbol_values=out5,\n",
        "    operators=ops_tensor)).numpy()\n",
        "\n",
        "average_cost_function_values = [\n",
        "    one_vals, two_vals, three_vals, four_vals, five_vals\n",
        "]\n",
        "std_of_param_guess = [\n",
        "    tf.math.reduce_std(out1).numpy(),\n",
        "    tf.math.reduce_std(out2).numpy(),\n",
        "    tf.math.reduce_std(out3).numpy(),\n",
        "    tf.math.reduce_std(out4).numpy(),\n",
        "    tf.math.reduce_std(out5).numpy()\n",
        "]\n",
        "\n",
        "print('-' * 80)\n",
        "print('Average cost function values for each guess number across unseen instances:',\n",
        "      average_cost_function_values)\n",
        "print('Variance of parameter values guessed:', std_of_param_guess)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvs5E__KhEHu",
        "colab_type": "text"
      },
      "source": [
        "Explore a singular instances. Now this instance is on 12 qubits and not just 10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWMazq46hBB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_graph_circuit, parameters, test_graph_op = generate_data(12, 1)\n",
        "\n",
        "test_graph_circuit = test_graph_circuit[0]\n",
        "test_graph_op = test_graph_op[0][0]\n",
        "\n",
        "resolution = 100\n",
        "input_vals = []\n",
        "for i, a in enumerate(np.linspace(-0.5, .5, resolution)):\n",
        "    for j, b in enumerate(np.linspace(-0.5, .5, resolution)):\n",
        "        input_vals.append([a, b])\n",
        "\n",
        "cost_vals = tfq.layers.Expectation()(test_graph_circuit,\n",
        "                                     symbol_names=parameters,\n",
        "                                     symbol_values=np.array(input_vals),\n",
        "                                     operators=test_graph_op).numpy()\n",
        "\n",
        "output_vals = np.empty((resolution, resolution))\n",
        "for i, a in enumerate(np.linspace(-0.5, 0.5, resolution)):\n",
        "    for j, b in enumerate(np.linspace(-0.5, 0.5, resolution)):\n",
        "        output_vals[i][j] = cost_vals[i * resolution + j]\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(output_vals)\n",
        "\n",
        "guess_0, guess_1, guess_2, guess_3, guess_4, _ = model([\n",
        "    tfq.convert_to_tensor([test_graph_circuit]),\n",
        "    tfq.convert_to_tensor([[test_graph_op]]),\n",
        "    np.zeros((1, 25)).astype(np.float32),\n",
        "    np.zeros((1, 2)).astype(np.float32),\n",
        "    np.zeros((1, 25)).astype(np.float32),\n",
        "])\n",
        "all_guesses = [guess_0, guess_1, guess_2, guess_3, guess_4]\n",
        "all_guesses = [list(a.numpy()[0]) for a in all_guesses]\n",
        "\n",
        "\n",
        "# This should be cleaned up...\n",
        "def f(x):\n",
        "    sim = cirq.Simulator()\n",
        "    final_state = sim.simulate(test_graph_circuit, {\n",
        "        parameters[0]: x[0],\n",
        "        parameters[1]: x[1]\n",
        "    }).final_state\n",
        "    q = sorted(list(test_graph_circuit.all_qubits()))\n",
        "    res = test_graph_op.expectation_from_wavefunction(\n",
        "        final_state, qubit_map={h: i for i, h in enumerate(q)}).real\n",
        "    return res\n",
        "\n",
        "\n",
        "all_costs = [f(a) for a in all_guesses]\n",
        "\n",
        "plt.plot((np.array(all_guesses)[:, 0] + 0.5) * resolution,\n",
        "         (np.array(all_guesses)[:, 1] + 0.5) * resolution,\n",
        "         c='r',\n",
        "         linestyle='--',\n",
        "         markevery=[4],\n",
        "         marker='*',\n",
        "         markersize=20,\n",
        "         linewidth=3.5)\n",
        "plt.show()\n",
        "\n",
        "print('All guesses for test graph:', all_guesses)\n",
        "print('Cost function values for test graph:', all_costs)\n",
        "print('-' * 80)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__ae8ksZdTkb",
        "colab_type": "text"
      },
      "source": [
        "As we can see from the above visual the RNN immediately begins guessing near the basin of attraction and continues to explore around the region looking to improve the estimate. Note the values in `all_costs` decreasing."
      ]
    }
  ]
}