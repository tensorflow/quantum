{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of TFQ_Example_DNN_LSTM_Qcontrol_application.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0_gMI4Blbe8",
        "colab_type": "text"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Quantum Authors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbL8NoC4IoNd",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bogCr-sSkXM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wppQ3TJ23mWC",
        "colab_type": "text"
      },
      "source": [
        "# A Hybrid Quantum-Classical Optimization for Quantum Control Optimization\n",
        "\n",
        "Author : Murphy Yuezhen Niu\n",
        "\n",
        "Created : 2020-Feb-01\n",
        "\n",
        "Last updated : 2020-Feb-27"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngDCx3sUlmlA",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/quantum/blob/research/control/control.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AUS_ZuopGz5",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Now that the basics are understood, let's show how one might use TFQ to construct a **hybrid quantum-classical neural net** for quantum control.\n",
        "\n",
        "In the first problem, we train a classical deep neural net to control a single qubit for realizing an arbitrary unitary; the output of the classical neural network determines the parameters of the quantum circuit to be applied to the qubit, which is then measured to produce the expectation values of different measurement operators.\n",
        "\n",
        "In the second problem, we train a recurrent neural network, to learn to predict the future quantum dynamics based on past obervations of a noisy implementation of quantum circuit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJa9sPPckfqS",
        "colab_type": "text"
      },
      "source": [
        "## Installation and imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFqxhKypZoSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade tensorflow==2.3.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcDb1zbSdXKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-quantum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enZ300Bflq80",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_quantum as tfq\n",
        "import cirq\n",
        "import sympy\n",
        "import cmath\n",
        "import numpy as np\n",
        "from scipy import linalg\n",
        "\n",
        "# visualization tools\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from cirq.contrib.svg import SVGCircuit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8J6c2-DVXQdr",
        "colab_type": "text"
      },
      "source": [
        "## Problem 1: Gate decomposition with DNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzfSYDfAcJTB",
        "colab_type": "text"
      },
      "source": [
        "### 1.1 Problem definition.\n",
        "\n",
        "More specifically, we provide an example of training a classical neural network to learn the Bloch Theorem: any single qubit unitary transformation can be realized by three single qubit rotations around two different angles.\n",
        "\n",
        "\n",
        "Given the specification of the single qubit unitary in regard to three parameters $\\phi, \\theta_1, \\theta_2$ that specifies the block sphere as the input to the classical neural network: the neural network will output rotation angles along two different axis ( $Ry$, and $Rz$) that realizes the given rotation. If we include a penalty term on the number of non-zero rotations, the training of a classical neural network should be able to find the most optimal.\n",
        "\n",
        "<img src=\"https://i.imgur.com/LX134rt.png\" width=\"1000\">\n",
        "\n",
        "This idealized version of a real quantum control problem where a classical neural network is learning a physical law of optimal decomposition of single-qubit unitaries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2TQJMt1HOhF",
        "colab_type": "text"
      },
      "source": [
        "Up to a global phase, an arbitrary single-qubit unitary can be specified in terms of three angles $\\phi$, $\\theta_1$, and $\\theta_2$ as $U=\\exp(-i \\phi (\\cos(\\theta_1)Z + \\sin(\\theta_1)(\\cos(\\theta_2)X + \\sin(\\theta_2)Y))$.\n",
        "\n",
        "It is possible to realize an arbitrary unitary of this form using three rotations about only two axes, $U = R_z(\\beta)R_y(\\gamma)R_z(\\delta)$.  There exists an analytic solution mapping $\\{\\phi, \\theta_1, \\theta_2\\}$ to $\\{\\beta, \\gamma, \\delta\\}$; however, for more sophisticated control problems, such an analytic mapping may not be available.  Therefore we investigate training neural networks to perform the control.  First we consider training a purely classical neural network to perform the mapping from unitary parameters to rotation angles.  Then, we consider training a hybrid quantum-classical network directly on expectation value data.\n",
        "\n",
        "First, we define the map from $\\{\\phi, \\theta_1, \\theta_2\\}$ to the associated unitary:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PU_dl3iPVylT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_unitary_from_params(phi, theta_1, theta_2):\n",
        "  return linalg.expm(-1j*phi*(\n",
        "      np.cos(theta_1)*cirq.Z._unitary_()\n",
        "      + np.sin(theta_1)*(\n",
        "          np.cos(theta_2)*cirq.X._unitary_()\n",
        "          + np.sin(theta_2)*cirq.Y._unitary_()\n",
        "      )\n",
        "  ))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjQXFVuM4Kim",
        "colab_type": "text"
      },
      "source": [
        "### 1.2 Physics model construction\n",
        "\n",
        "#### Following lines are analytic solution to the Bloch theorem, where batch input is the input to a unitary parameterized by $U=\\exp(-i \\phi (cos(\\theta_1)Z + \\sin(\\theta_1)(\\cos(\\theta_2)X + \\sin(\\theta_2)Y))$, the output is the angle $\\beta, \\gamma, \\delta$ for the Z Y Z rotations that realizes the target unitary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sJ7NKALZ8oJ",
        "colab_type": "text"
      },
      "source": [
        "Next, we write down the known mapping between the angles $\\{\\phi, \\theta_1, \\theta_2\\}$ and the two-axis control angles $\\{\\beta, \\gamma, \\delta\\}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPQkoK93HTFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def map_unitary_params(phi, theta_1, theta_2):\n",
        "  \"\"\"Convert unitary angles into two-axis control angles.\"\"\"\n",
        "  #### Below works ONLY when all input angles are less than pi\n",
        "\n",
        "  gamma = -2*np.arccos(-np.sqrt(3 + np.cos(2 * theta_1)  + 2 * np.sin(theta_1) ** 2 * np.cos(phi* 2) )/2.0)\n",
        "\n",
        "  delta = 2*np.real(-  1j * np.log(-(-1.0) ** (1/4) *np.sqrt(- np.exp(1j * phi) * (-1 + np.exp(2 * 1j * phi))   * \n",
        "                                                              np.sqrt(3 + np.cos(2 * theta_1)  + 2 * np.sin(theta_1) ** 2 * np.cos(phi* 2) )) /\n",
        "                                      2 / np.sqrt(-np.exp(1j * ( 2 *phi+ theta_2)) * np.sin(phi) ** 2 \n",
        "                                                  * (np.cos(theta_1) + 1j / np.tan(phi))) ))\n",
        "\n",
        "  beta = 2*np.real(-  1j * np.log(- np.exp(1j * ( phi+ theta_2)) * \n",
        "                                      np.sqrt(-1j * np.exp(1j * phi)*(-1 + np.exp(2 * 1j * phi))\n",
        "                                      *np.sqrt(3 + np.cos(2 * theta_1)  + 2 * np.sin(theta_1) ** 2 * np.cos(phi* 2) ))\n",
        "                                      * np.sin(phi)/(-1 + np.exp(2 * 1j * phi)) /\n",
        "                                      np.sqrt(- np.exp(1j * (2 * phi+ theta_2)) * np.sin(phi) *( np.sin(phi) * np.cos(theta_1) + 1j * np.cos(phi) )) ))\n",
        "\n",
        "  return beta, gamma, delta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zh0vypmLpLWe",
        "colab_type": "text"
      },
      "source": [
        "Build a function to generate training data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPxwDSubpOcm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_angles_training_data(batch_size):\n",
        "    data = []\n",
        "    labels = []\n",
        "    for _ in range(batch_size):\n",
        "      random_unitary_params = np.random.uniform(0,  np.pi, (3)).tolist()\n",
        "      beta, gamma, delta = map_unitary_params(*random_unitary_params)\n",
        "      data.append(random_unitary_params)\n",
        "      labels.append([beta, gamma, delta])\n",
        "    return data, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KnTDJ138e5m",
        "colab_type": "text"
      },
      "source": [
        "Using this function, set up the training and validation data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unUaBFTo8hRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_size = 10000\n",
        "validation_size = 10000\n",
        "all_commands, all_expectations = get_angles_training_data(train_size + validation_size)\n",
        "\n",
        "commands_train = all_commands[:train_size]\n",
        "expectations_train = all_expectations[:train_size]\n",
        "commands_val = all_commands[-validation_size:]\n",
        "expectations_val = all_expectations[-validation_size:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkcRVIXTjLx1",
        "colab_type": "text"
      },
      "source": [
        "Run a test to confirm that all training data is correct.  We do this by checking the Hilbert-Schmidt inner product $\\langle U_i, U_o\\rangle = \\text{Tr}\\left(U_o^\\dagger U_i\\right)$ between the two resulting matrices:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYJ8MHPLjLU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "q = cirq.GridQubit(0, 0)\n",
        "for data_angles, label_angles in zip(commands_train, all_expectations):\n",
        "  test_phi, test_theta_1, test_theta_2 = data_angles\n",
        "  beta = label_angles[0]\n",
        "  gamma = label_angles[1]\n",
        "  delta = label_angles[2]\n",
        "  u_i = get_unitary_from_params(test_phi, test_theta_1, test_theta_2)\n",
        "  u_o = np.matmul(cirq.rz(beta)._unitary_(),\n",
        "      np.matmul(cirq.ry(gamma)._unitary_(), cirq.rz(delta)._unitary_()))\n",
        "\n",
        "  circuit = cirq.Circuit(cirq.rz(delta)(q), cirq.ry(gamma)(q), cirq.rz(beta)(q))\n",
        " \n",
        "  check1= np.trace(np.matmul(u_o.conj().T, circuit.unitary())) ** 2 / 4.0\n",
        "\n",
        "  check = np.trace(np.matmul(u_o.conj().T, u_i))** 2 / 4.0\n",
        "\n",
        "  if (abs(abs(check) - 1) > 1e-5) and (abs(abs(check1) - 1) > 1e-5):\n",
        "    print(\"Inner product value:\")\n",
        "    print(check)\n",
        "    print(\"Input angles quadrant check:\")\n",
        "    print([int(test_phi>np.pi), int(test_theta_1>np.pi), int(test_theta_2>np.pi)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iV85ahKKCuQw",
        "colab_type": "text"
      },
      "source": [
        "### 1.3 Prepare the training data set based on input and expectation values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFIbFhOgalLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_expectation_training_data(batch_size):\n",
        "    q = cirq.GridQubit(0, 0)\n",
        "    beta_s, gamma_s, delta_s = sympy.symbols(\"beta gamma delta\")\n",
        "    circuit = cirq.Circuit(cirq.rz(delta_s)(q), cirq.ry(gamma_s)(q), cirq.rz(beta_s)(q))\n",
        "    ops = [cirq.X(q), cirq.Y(q), cirq.Z(q)]\n",
        "\n",
        "    params = []\n",
        "    outputs = []\n",
        "    for _ in range(batch_size):\n",
        "      random_unitary_params = np.random.uniform(0,  np.pi, (3)).tolist()\n",
        "      beta, gamma, delta = map_unitary_params(*random_unitary_params)\n",
        "      expectations = tfq.layers.Expectation()(\n",
        "          circuit,\n",
        "          symbol_names=[beta_s, gamma_s, delta_s],\n",
        "          symbol_values=[[beta, gamma, delta]],\n",
        "          operators=ops \n",
        "      ).numpy().tolist()[0]\n",
        "      params.append(random_unitary_params)\n",
        "      outputs.append(expectations)\n",
        "    return params, outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OLc2MB-jOuD",
        "colab_type": "text"
      },
      "source": [
        "We now define the hybrid network that will be trained to perform the qubit control.  Note that we restrict the gate set of the quantum portion of the net to alternating $R_z$ and $R_y$ gates.  By adding a term to the loss that induces sparsity on the controls of these gates, the hope is that the hybrid network will learn the optimal two-axis control (which requires only three angles)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUG8Hct01KUg",
        "colab_type": "text"
      },
      "source": [
        "### 1.4 Build a quantum-classical hybrid neural network to control the rotations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ua2iaypA9YYz",
        "colab_type": "text"
      },
      "source": [
        "#### quantum part of the network:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyuqEa9C9bCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# parameters that the classical NN will feed values into\n",
        "control_params = sympy.symbols(['theta_{}'.format(n) for n in range(7)])\n",
        "\n",
        "# create the parameterized circuit\n",
        "qubit = cirq.GridQubit(0, 0)\n",
        "two_axis_control_circuit = cirq.Circuit(\n",
        "    cirq.rz(control_params[2])(qubit),\n",
        "    cirq.ry(control_params[1])(qubit),\n",
        "    cirq.rz(control_params[0])(qubit)\n",
        ")\n",
        "\n",
        "# Measurement will be three-axis\n",
        "pauli_x = cirq.PauliString(cirq.X(qubit))\n",
        "pauli_y = cirq.PauliString(cirq.Y(qubit))\n",
        "pauli_z = cirq.PauliString(cirq.Z(qubit))\n",
        "measure_list = [pauli_x, pauli_y, pauli_z]\n",
        "\n",
        "# Display the circuit\n",
        "SVGCircuit(two_axis_control_circuit)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEwrVek41MZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(y_true,y_pred ):\n",
        "    return -tf.math.log(tf.reduce_mean(tf.square(y_pred - y_true), axis=-1)) #+ 0.1 * tf.reduce_sum(tf.square(tf.math.tanh(dense_3)), axis=-1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "circuits_input = tf.keras.Input(shape=(), dtype=tf.dtypes.string, name='circuits_input')\n",
        "commands_input = tf.keras.Input((3,), name='commands_input')\n",
        "dense_layer_1 = tf.keras.layers.Dense(128, activation='relu', name='dense_layer_1')(commands_input)\n",
        "dense_layer_2 = tf.keras.layers.Dense(128, name='dense_layer_2')(dense_layer_1)\n",
        "dense_layer_3 = tf.keras.layers.Dense(64, activation='relu', name='dense_layer_3')(dense_layer_2) \n",
        "angles_layer = tf.keras.layers.Dense(3,  activation='linear', name='angles_layer')(dense_layer_3)\n",
        "\n",
        "measured_expectations = tfq.layers.ControlledPQC(\n",
        "    two_axis_control_circuit, measure_list)([circuits_input, angles_layer])\n",
        "two_axis_control_model = tf.keras.Model(inputs=[circuits_input, commands_input], outputs=measured_expectations)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dL0wVKys4kYw",
        "colab_type": "text"
      },
      "source": [
        "Set up data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRqW1lmkYEMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_size = 10000\n",
        "validation_size = 10000\n",
        "all_commands, all_expectations = get_expectation_training_data(train_size + validation_size)\n",
        "\n",
        "commands_train = all_commands[:train_size]\n",
        "expectations_train = all_expectations[:train_size]\n",
        "commands_val = all_commands[-validation_size:]\n",
        "expectations_val = all_expectations[-validation_size:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziAd64oNYH3D",
        "colab_type": "text"
      },
      "source": [
        "Perform optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ig-95OfT2AYG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 200\n",
        "batch_size = 1000\n",
        "lr=0.010 \n",
        "\n",
        "two_axis_control_model.compile(tf.keras.optimizers.Adam(learning_rate=lr, decay=lr / epochs), \n",
        "              loss='mse')\n",
        "history_two_axis = two_axis_control_model.fit(\n",
        "    x=[tfq.convert_to_tensor([cirq.Circuit()]*train_size), tf.convert_to_tensor(commands_train)],\n",
        "    y=tf.convert_to_tensor(expectations_train), batch_size=batch_size, epochs=epochs,\n",
        "    validation_data=(\n",
        "        [tfq.convert_to_tensor([cirq.Circuit()]*validation_size), tf.convert_to_tensor(commands_val)],\n",
        "                               tf.convert_to_tensor(expectations_val)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcVcyv3V-rAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history_two_axis.history['loss'])\n",
        "plt.title(\"Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Error in Control\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history_two_axis.history['val_loss'])\n",
        "plt.title(\"Validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Error in Control\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBVLQZRBd4M4",
        "colab_type": "text"
      },
      "source": [
        "## 2. LSTM for learning time-dependent quantum noise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4hiTZTheWaq",
        "colab_type": "text"
      },
      "source": [
        "## 2.0 Model definition."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMsuJCzDGPqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(batch_size, rnn_units, stateful=False): \n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.LSTM(\n",
        "           rnn_units,\n",
        "          return_sequences=True,\n",
        "          stateful=stateful,\n",
        "          recurrent_initializer='glorot_uniform',\n",
        "          batch_input_shape=[batch_size, None, 1]),\n",
        "      tf.keras.layers.Dense(1)\n",
        "  ])\n",
        "  return model \n",
        "\n",
        "def train_lstm(data, batch_size, rnn_units, epochs, learning_rate):\n",
        "  print('Start training.')\n",
        "  model = build_model(batch_size, rnn_units)\n",
        "\n",
        "  def loss(labels, logits):\n",
        "    return tf.keras.losses.binary_crossentropy(labels, logits, True)\n",
        "\n",
        " \n",
        "  optimizer = tf.keras.optimizers.Adamax( learning_rate) \n",
        "  model.compile(optimizer=optimizer, loss=loss)\n",
        "  model.summary()\n",
        " \n",
        " \n",
        "  model.fit(data, epochs= epochs)\n",
        "  eval_loss = model.evaluate(data)\n",
        "  print( \"final loss = \", eval_loss)\n",
        "  return model\n",
        "\n",
        "\n",
        "def sample_eval(weights,  eval_samples, epoch, rnn_units, input_lenth):\n",
        "  model = build_model( batch_size, rnn_units, True)\n",
        "  model.build(tf.TensorShape([ batch_size, None, 1]))\n",
        "  model.set_weights(weights)\n",
        "  # Whole sequence sampling and fidelity\n",
        "  eval_samples = eval_samples //  batch_size *  batch_size\n",
        "  sample_data = np.zeros(((eval_samples,  input_length)), np.float64)\n",
        "  sample_n = 0\n",
        "  model.summary()\n",
        "\n",
        "  while sample_n < eval_samples:\n",
        "    model.reset_states()\n",
        "    input_eval = tf.zeros([ batch_size, 1, 1])\n",
        "    output_eval = tf.reshape(model(input_eval), [ batch_size])\n",
        "    output_prob = 1 / (1 + np.exp(-output_eval.numpy()))\n",
        "    sample_data[sample_n:sample_n +  batch_size,\n",
        "                0] =output_prob\n",
        "    for i in range( input_length - 1):\n",
        "      input_eval = tf.cast(\n",
        "          tf.reshape(sample_data[sample_n:sample_n +  batch_size, i],\n",
        "                     [ batch_size, 1, 1]), tf.float32)\n",
        "      output_eval = tf.reshape(model(input_eval), [ batch_size])\n",
        "      output_prob = 1 / (1 + np.exp(-output_eval.numpy()))\n",
        "      sample_data[sample_n:sample_n +  batch_size,\n",
        "                  i + 1] = np.random.binomial(1, output_prob)\n",
        "    sample_n +=  batch_size\n",
        " \n",
        "\n",
        "\n",
        "def generate_data(data_time, data_length, omega_0, exponent, alpha):\n",
        "\n",
        "  timesteps = np.linspace(0.02, data_time, data_length)\n",
        "  q = cirq.GridQubit(0, 0)\n",
        "  phase_s = sympy.symbols(\"phaseshift\")\n",
        "  circuit = cirq.Circuit(cirq.H(q), cirq.Rz(phase_s)(q))\n",
        "  ops = [cirq.X(q)]\n",
        "\n",
        "  params = []\n",
        "  outputs = np.zeros(data_length)\n",
        "\n",
        "  for i in range(data_length):\n",
        "    phaseshift = timesteps[i] * omega_0 + alpha * timesteps[i] ** (exponent +1) / (exponent +1)\n",
        "    expectations = tfq.layers.Expectation()(\n",
        "        circuit,\n",
        "        symbol_names=[phase_s],\n",
        "        symbol_values=[[phaseshift]],\n",
        "        operators=ops \n",
        "    ).numpy().tolist()[0]\n",
        "     \n",
        "    outputs[i]= expectations[0] \n",
        "  return outputs\n",
        "     \n",
        "def load_data(data_size, data_time, data_length, alpha_min, alpha_max, omega_0, exponent):\n",
        "  alpha_list = np.linspace(alpha_min, alpha_max, data_size)\n",
        "  train_data = []\n",
        "  for k in range(data_size):\n",
        "    data1 = generate_data(data_time, data_length, omega_0, exponent, alpha_list[k])\n",
        "    train_data.append(data1)\n",
        "  return np.array(train_data)\n",
        "\n",
        "   \n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCbdEZ4qeDty",
        "colab_type": "text"
      },
      "source": [
        "### 2.1 Generate training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFLQEJ4r9uP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epoch = 30\n",
        "batch_size = 60\n",
        "learning_rate = 0.001\n",
        "\n",
        "rnn_units = 256\n",
        "data_size = 500\n",
        "alpha_min = 0.031\n",
        "alpha_max = 0.2\n",
        "exponent = 0.5\n",
        "omega_0 = 0.7 \n",
        "data_time = 0.5 / alpha_min\n",
        "data_length = 40\n",
        " \n",
        "\n",
        "train_data = load_data(data_size, data_time, data_length, alpha_min, alpha_max, omega_0, exponent)  # this should be a numpy array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBNZYAO6edop",
        "colab_type": "text"
      },
      "source": [
        "## 2.2 Training the LSTM model on the time-dependent expectation values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikQ6MXZaec4B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = tf.data.Dataset.from_tensor_slices(train_data)\n",
        "\n",
        "def build_example(chunk):\n",
        "  input_seq = tf.cast(tf.concat([[0], chunk], 0), tf.float32)\n",
        "  target = tf.concat([chunk, [0]], 0)\n",
        "  input_seq = input_seq[:-1]\n",
        "  target = target[:-1]\n",
        "  return tf.expand_dims(input_seq, 1), tf.expand_dims(target, 1)\n",
        "BUFFER_SIZE = 100\n",
        "data = data.map(build_example).shuffle(BUFFER_SIZE).batch(\n",
        "    batch_size, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89_k81SYxKFt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = train_lstm(data, batch_size, rnn_units, epoch, learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3a12DaDnKBg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(model.history.history['loss']) \n",
        "plt.xlabel(\"Training Epochs\", fontsize='14')\n",
        "plt.ylabel(\"Error in LSTM samples\", fontsize='14')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}