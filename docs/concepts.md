# Quantum machine learning concepts

Google's
<a href="https://ai.googleblog.com/2019/10/quantum-supremacy-using-programmable.html" class="external">quantum beyond-classical experiment</a>
used 53&nbsp;*noisy*&nbsp;qubits to demonstrate it could perform a calculation
in 200 seconds on a quantum computer that would take 10,000 years on the largest
classical computer using existing algorithms. This marks the beginning of the
<a href="https://quantum-journal.org/papers/q-2018-08-06-79/" class="external">Noisy Intermediate-Scale Quantum</a>&nbsp;(NISQ)
computing era. In the coming years, quantum devices with tens-to-hundreds of
noisy qubits are expected to become a reality.

## Quantum computing

Quantum computing relies on properties of quantum mechanics to compute problems
that would be out of reach for classical computers. A quantum computer uses
*qubits*. Qubits are like regular bits in a computer, but with the added ability
to be put into a *superposition* and share *entanglement* with one another.

Classical computers perform deterministic classical operations or can emulate
probabilistic processes using sampling methods. By harnessing superposition and
entanglement, quantum computers can perform quantum operations that are
difficult to emulate at scale with classical computers. Ideas for leveraging
NISQ quantum computing include optimization, quantum simulation, cryptography,
and machine learning.


## Quantum machine learning

*Quantum machine learning* (QML) is built on two concepts: *quantum data* and
*hybrid quantum-classical models*.

### Quantum data

*Quantum data* is any data source that occurs in a natural or artificial quantum
system. This can be data generated by a quantum computer, like the samples
gathered from the
<a href="https://www.nature.com/articles/s41586-019-1666-5" class="external">Sycamore processor</a>
for Google’s demonstration of quantum supremacy. Quantum data exhibits
superposition and entanglement, leading to joint probability distributions that
could require an exponential amount of classical computational resources to
represent or store. The quantum supremacy experiment showed it is possible to
sample from an extremely complex joint probability distribution of 2^53 Hilbert
space.

The quantum data generated by NISQ processors are noisy and typically entangled
just before the measurement occurs. Heuristic machine learning techniques can
create models that maximize extraction of useful classical information from
noisy entangled data. The TensorFlow Quantum (TFQ) library provides primitives
to develop models that disentangle and generalize correlations in quantum
data—opening up opportunities to improve existing quantum algorithms or discover
new quantum algorithms.

The following are examples of quantum data that can be generated or simulated on
a quantum device:

- *Chemical simulation* —Extract information about chemical structures and
  dynamics with potential applications to material science, computational
  chemistry, computational biology, and drug discovery.
- *Quantum matter simulation* —Model and design high temperature
  superconductivity or other exotic states of matter which exhibits many-body
  quantum effects.
- *Quantum control* —Hybrid quantum-classical models can be variationally
  trained to perform optimal open or closed-loop control, calibration, and error
  mitigation. This includes error detection and correction strategies for
  quantum devices and quantum processors.
- *Quantum communication networks* —Use machine learning to discriminate among
  non-orthogonal quantum states, with application to design and construction of
  structured quantum repeaters, quantum receivers, and purification units.
- *Quantum metrology* —Quantum-enhanced high precision measurements such as
  quantum sensing and quantum imaging are inherently done on probes that are
  small-scale quantum devices and could be designed or improved by variational
  quantum models.

### Hybrid quantum-classical models

A quantum model can represent and generalize data with a quantum mechanical
origin. Because near-term quantum processors are still fairly small and noisy,
quantum models cannot generalize quantum data using quantum processors alone.
NISQ processors must work in concert with classical co-processors to become
effective. Since TensorFlow already supports heterogeneous computing across
CPUs, GPUs, and TPUs, it is used as the base platform to experiment with hybrid
quantum-classical algorithms.

A *quantum neural network* (QNN) is used to describe a parameterized quantum
computational model that is best executed on a quantum computer. This term is
often interchangeable with *parameterized quantum circuit* (PQC).


## Research

During the NISQ-era, quantum algorithms with known speedups over classical
algorithms—like
<a href="https://arxiv.org/abs/quant-ph/9508027" class="external">Shor's factoring algorithm</a> or
<a href="https://arxiv.org/abs/quant-ph/9605043" class="external">Grover's search algorithm</a>—are
not yet possible at a meaningful scale.

A goal of TensorFlow Quantum is to help discover algorithms for the NISQ-era,
with particular interest in:

1. *Use classical machine learning to enhance NISQ algorithms.* The hope is that
   techniques from classical machine learning can enhance our understanding of
   quantum computing. In
   <a href="https://arxiv.org/abs/1907.05415" class="external">meta-learning for quantum neural networks via classical recurrent neural networks</a>,
   a recurrent neural network (RNN) is used to discover that optimization of
   the control parameters for algorithms like the QAOA and VQE are more efficient
   than simple off the shelf optimizers. And
   <a href="https://www.nature.com/articles/s41534-019-0141-3" class="external">machine learning for quantum control</a>
   uses reinforcement learning to help mitigate errors and produce higher
   quality quantum gates.
2. *Model quantum data with quantum circuits.* Classically modeling quantum data
   is possible if you have an exact description of the datasource—but sometimes
   this isn’t possible. To solve this problem, you can try modeling on the
   quantum computer itself and measure/observe the important statistics.
   <a href="https://www.nature.com/articles/s41567-019-0648-8" class="external">Quantum convolutional neural networks</a>
   shows a quantum circuit designed with a structure analogous to a
   convolutional neural network (CNN) to detect different topological phases of
   matter. The quantum computer holds the data and the model. The classical
   processor sees only measurement samples from the model output and never the
   data itself. In
   <a href="https://arxiv.org/abs/1711.07500" class="external">Robust entanglement renormalization on a noisy quantum computer</a>,
   the authors learn to compress information about quantum many-body systems
   using a DMERA model.

Other areas of interest in quantum machine learning include:

* Modeling purely classical data on quantum computers.
* Quantum-inspired classical algorithms.
* <a href="https://arxiv.org/abs/1810.03787" class="external">Supervised learning with quantum classifiers</a>.
* Adaptive layer-wise learning for quantum neural network.
* <a href="https://arxiv.org/abs/1909.12264" class="external">Quantum dynamics learning</a>.
* <a href="https://arxiv.org/abs/1910.02071" class="external">Generative modeling of mixed quantum states</a> .
* <a href="https://arxiv.org/abs/1802.06002" class="external">Classification with quantum neural networks on near term processors</a>.
