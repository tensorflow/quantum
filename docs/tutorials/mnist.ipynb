{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5rc1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xLOXFOT5Q40E"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "iiQkM5ZgQ8r2",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j6331ZSsQGY3"
      },
      "source": [
        "# MNIST classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "i9Jcnb8bQQyd"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/quantum/tutorials/mnist\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/quantumlib/TFQuantum/blob/master/docs/tutorials/mnist.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/quantumlib/TFQuantum/blob/master/docs/tutorials/mnist.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_quantum/docs/tutorials/mnist.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udLObUVeGfTs",
        "colab_type": "text"
      },
      "source": [
        "This tutorial builds a quantum neural network (QNN) to classify a simplified version of MNIST, similar to the approach used in <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al</a>. The performance of the quantum neural network on this classical data problem is compared with a classical neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X35qHdh5Gzqg",
        "colab_type": "text"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Download and install the required packages:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fAVlg7rxkvUw",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install --upgrade pip\n",
        "!pip install cirq==0.7.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TorxE5tnkvb2",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install --upgrade tensorflow==2.0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FxkQA6oblNqI"
      },
      "source": [
        "Note: If the following code cell fails, execute the first code cells and then restart the Colab runtime (*Runtime > Restart Runtime*)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "saFHsRDpkvkH",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "h = \"2dfcfceb9726fa73c40381c037dc01facd3d061e\"\n",
        "!cd ~/\n",
        "!rm -r -f TFQuantum/\n",
        "!git clone https://{h}:{h}@github.com/quantumlib/TFQuantum.git;cd TFQuantum/\n",
        "!pip install --upgrade ./TFQuantum/wheels/tfquantum-0.2.0-cp36-cp36m-linux_x86_64.whl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdgMMZEBGqyl",
        "colab_type": "text"
      },
      "source": [
        "Now import TensorFlow and the module dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "enZ300Bflq80",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_quantum as tfq\n",
        "\n",
        "import cirq\n",
        "import sympy\n",
        "import numpy as np\n",
        "import seaborn\n",
        "import collections\n",
        "\n",
        "# visualization tools\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from cirq.contrib.svg import SVGCircuit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b08Mmbs8lr81"
      },
      "source": [
        "## 1. Load the data\n",
        "\n",
        "Load the MNIST data distributed with Keras. Since this tutorial demonstrates a binary classification problem for the numbers 3 and 6, remove the other numbers. Then display the first training example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-XEU8egGL6q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "print(\"Number of original training examples:\", len(x_train))\n",
        "print(\"Number of original test examples:\", len(x_train))\n",
        "\n",
        "# Keep the 3s and 6s and remove the other numbers.\n",
        "x_train, y_train = zip(*((x, y) for x, y in zip(x_train, y_train) if y in [3, 6]))\n",
        "x_test, y_test = zip(*((x, y) for x, y in zip(x_test, y_test) if y in [3, 6]))\n",
        "\n",
        "print(\"Number of filtered training examples:\", len(x_train))\n",
        "print(\"Number of filtered test examples:\", len(x_test))\n",
        "\n",
        "print(y_train[0])\n",
        "seaborn.heatmap(x_train[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmmtplIFGL6t",
        "colab_type": "text"
      },
      "source": [
        "But an image size of 28x28 is much too large for current quantum computers. Resize the image down to 4x4 and scale the numbers between 0 and 1:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR4tKxLOGL6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reduce_image(x):\n",
        "    x = tf.reshape(x, [1, 28, 28, 1])\n",
        "    x = tf.image.resize(x, [4, 4])\n",
        "    x = tf.reshape(x, [4, 4])\n",
        "    x = x / 255\n",
        "    return x.numpy()\n",
        "\n",
        "\n",
        "x_train = [reduce_image(x) for x in x_train]\n",
        "x_test = [reduce_image(x) for x in x_test]\n",
        "\n",
        "\n",
        "# Remove examples where the same input has multiple labels.\n",
        "def remove_contradicting(xs, ys):\n",
        "    mapping = collections.defaultdict(set)\n",
        "    for x, y in zip(xs, ys):\n",
        "        mapping[str(x)].add(y)\n",
        "    return zip(*((x, y) for x, y in zip(xs, ys) if len(mapping[str(x)]) == 1))\n",
        "\n",
        "\n",
        "x_train, y_train = remove_contradicting(x_train, y_train)\n",
        "x_test, y_test = remove_contradicting(x_test, y_test)\n",
        "\n",
        "print(\"Number of non-contradicting training examples: \", len(x_train))\n",
        "print(\"Number of non-contradicting test examples: \", len(x_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOMd7zIjGL6x",
        "colab_type": "text"
      },
      "source": [
        "Again, display the first training exampleâ€”after resize: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIYOtCRIGL6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(y_train[0])\n",
        "seaborn.heatmap(x_train[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3kBLeodGL61",
        "colab_type": "text"
      },
      "source": [
        "To process images using a quantum computer, <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> proposed representing each pixel with a qubit, with the state depending on the value of the pixel.\n",
        "\n",
        "To classify these images, <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> proposed taking the expectation of a readout qubit in a parameterized circuit. The expectation returns a value between 1 and -1, so choosing 1 and -1 as the targets is natural."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOu_3-3ZGL61",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_to_circuit(image):\n",
        "    \"\"\"Encode truncated classical image into quantum datapoint.\"\"\"\n",
        "    values = np.ndarray.flatten(image)\n",
        "    qubits = cirq.GridQubit.rect(4, 4)\n",
        "    circuit = cirq.Circuit()\n",
        "    for i, value in enumerate(values):\n",
        "        if value > 0.5:\n",
        "            circuit.append(cirq.X(qubits[i]))\n",
        "    return circuit\n",
        "\n",
        "\n",
        "x_train = [convert_to_circuit(x) for x in x_train]\n",
        "x_test = [convert_to_circuit(x) for x in x_test]\n",
        "\n",
        "\n",
        "def convert_label(y):\n",
        "    if y == 3:\n",
        "        return 1.0\n",
        "    else:\n",
        "        return -1.0\n",
        "\n",
        "\n",
        "y_train = [convert_label(y) for y in y_train]\n",
        "y_test = [convert_label(y) for y in y_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zkr6jVDgGL64",
        "colab_type": "text"
      },
      "source": [
        "And display the circuit diagram for the first example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qP-wmm-0GL65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(y_train[0])\n",
        "print(x_train[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4USiqeOqGL67",
        "colab_type": "text"
      },
      "source": [
        "## 2. Quantum neural network\n",
        "\n",
        "There is little guidance for a quantum circuit structure that classifies images. Since the classification is based on the expectation of the readout qubit, <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> propose using two qubit gates, with the readout qubit always acted upon.\n",
        "\n",
        "This following example shows this layer approach. It uses *n* instances of the same gate, with each of the data qubits acting on the readout qubit:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiALbpwRGL69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_quantum_model():\n",
        "    \"\"\"Create a QNN model circuit and readout operation to go along with it.\"\"\"\n",
        "    data_qubits = cirq.GridQubit.rect(4, 4)\n",
        "    readout = cirq.GridQubit(16, 0)\n",
        "\n",
        "    symbols = []\n",
        "    circuit = cirq.Circuit()\n",
        "\n",
        "    # Generates a layer of the gate type.\n",
        "    def layer(gate, prefix):\n",
        "        for i, qubit in enumerate(data_qubits):\n",
        "            symbol = sympy.Symbol(prefix + '-' + str(i))\n",
        "            circuit.append(gate(qubit, readout)**symbol)\n",
        "            symbols.append(symbol)\n",
        "\n",
        "    # Prepare the readout qubit.\n",
        "    circuit.append(cirq.X(readout))\n",
        "    circuit.append(cirq.H(readout))\n",
        "\n",
        "    # Then add layers (experiment by adding more).\n",
        "    layer(cirq.XX, \"xx-1\")\n",
        "    layer(cirq.ZZ, \"zz-1\")\n",
        "\n",
        "    # Finally, prepare the readout qubit.\n",
        "    circuit.append(cirq.H(readout))\n",
        "\n",
        "    return circuit, cirq.Z(readout)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LY7vbY6yfABE",
        "colab_type": "text"
      },
      "source": [
        "Build the Keras model with the quantum components. This model is fed the \"quantum data\" that encodes the classical data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2xDsYpFGL7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the quantum components.\n",
        "model_circuit, model_readout = create_quantum_model()\n",
        "\n",
        "# Build the Keras model.\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Input(shape=(), dtype=tf.dtypes.string))\n",
        "model.add(tfq.layers.PQC(model_circuit, model_readout))\n",
        "\n",
        "# Define a custom accuracy that equals the sign of the output.\n",
        "@tf.function\n",
        "def custom_accuracy(y_true, y_pred):\n",
        "    y_true = tf.squeeze(y_true)\n",
        "    y_pred = tf.map_fn(lambda x: 1.0 if x >= 0 else -1.0, y_pred)\n",
        "    return tf.keras.backend.mean(tf.keras.backend.equal(y_true, y_pred))\n",
        "\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "model.compile(loss=tf.keras.losses.hinge,\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[custom_accuracy])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsuOzDYblA9s",
        "colab_type": "text"
      },
      "source": [
        "Reduce the dataset size for faster training. For better results, ignore this code cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8vuQpSLlBV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Comment out for increased accuracy.\n",
        "NUM_EXAMPLES = 500\n",
        "x_train = x_train[:NUM_EXAMPLES]\n",
        "y_train = y_train[:NUM_EXAMPLES]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMSdgGC1GL7D",
        "colab_type": "text"
      },
      "source": [
        "Using the full dataset, training this model should achieve >85% accuracy on the test set. Here, only `NUM_EXAMPLES` datapoints are used to save time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nl0aQ-w7GL7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Wrap the training and test sets so Keras can handle them.\n",
        "x_train = tfq.convert_to_tensor(x_train)\n",
        "x_test = tfq.convert_to_tensor(x_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          batch_size=32,\n",
        "          epochs=3,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "\n",
        "qnn_results = model.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8952YvuWGL7J",
        "colab_type": "text"
      },
      "source": [
        "## 3. Classical neural network\n",
        "\n",
        "While the quantum neural network works for this simplified MNIST problem, a basic classical neural network can easily outperform a QNN on this task. After a single epoch, a classical neural network can achieve >98% accuracy on the holdout set.\n",
        "\n",
        "In the following example, a classical neural network is used for a 10-class classification problem (instead of the 2-class problem for the QNN), and uses the entire 28x28 image instead of subsampling the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZofEHhLGL7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "\n",
        "def create_classical_model():\n",
        "    # A simple model based off LeNet from https://keras.io/examples/mnist_cnn/\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Reshape([28, 28, 1]))\n",
        "    model.add(tf.keras.layers.Conv2D(32, [3, 3], activation='relu'))\n",
        "    model.add(tf.keras.layers.Conv2D(64, [3, 3], activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.25))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "\n",
        "model = create_classical_model()\n",
        "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          batch_size=128,\n",
        "          epochs=1,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "\n",
        "cnn_results = model.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RH3mam7EGL7N",
        "colab_type": "text"
      },
      "source": [
        "## 4. Comparison\n",
        "\n",
        "Despite a more difficult problem, the classical neural network easily outperforms the quantum neural network. For classical data, it is difficult to beat a classical neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOMeN7pMGL7P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "qnn_accuracy = qnn_results[1]\n",
        "cnn_accuracy = cnn_results[1]\n",
        "\n",
        "seaborn.barplot([\"quantum\", \"classical\"], [qnn_accuracy, cnn_accuracy])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
