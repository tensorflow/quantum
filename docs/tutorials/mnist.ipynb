{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xLOXFOT5Q40E"
   },
   "source": [
    "##### Copyright 2020 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "iiQkM5ZgQ8r2"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j6331ZSsQGY3"
   },
   "source": [
    "# MNIST classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i9Jcnb8bQQyd"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/quantum/tutorials/mnist\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/quantum/blob/master/docs/tutorials/mnist.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/quantum/blob/master/docs/tutorials/mnist.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/quantum/docs/tutorials/mnist.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "udLObUVeGfTs"
   },
   "source": [
    "This tutorial builds a quantum neural network (QNN) to classify a simplified version of MNIST, similar to the approach used in <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al</a>. The performance of the quantum neural network on this classical data problem is compared with a classical neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X35qHdh5Gzqg"
   },
   "source": [
    "## Setup\n",
    "\n",
    "Download and install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TorxE5tnkvb2"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FxkQA6oblNqI"
   },
   "source": [
    "Note: If the following code cell fails, execute the first code cells and then restart the Colab runtime (*Runtime > Restart Runtime*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "saFHsRDpkvkH"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow-quantum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hdgMMZEBGqyl"
   },
   "source": [
    "Now import TensorFlow and the module dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "enZ300Bflq80"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_quantum as tfq\n",
    "\n",
    "import cirq\n",
    "import sympy\n",
    "import numpy as np\n",
    "import seaborn\n",
    "import collections\n",
    "\n",
    "# visualization tools\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from cirq.contrib.svg import SVGCircuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b08Mmbs8lr81"
   },
   "source": [
    "## 1. Load the data\n",
    "\n",
    "Load the MNIST data distributed with Keras. Since this tutorial demonstrates a binary classification problem for the numbers 3 and 6, remove the other numbers. Then display the first training example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p-XEU8egGL6q"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "print(\"Number of original training examples:\", len(x_train))\n",
    "print(\"Number of original test examples:\", len(x_train))\n",
    "\n",
    "# Keep the 3s and 6s and remove the other numbers.\n",
    "x_train, y_train = zip(*(\n",
    "    (x, y) for x, y in zip(x_train, y_train) if y in [3, 6]))\n",
    "x_test, y_test = zip(*((x, y) for x, y in zip(x_test, y_test) if y in [3, 6]))\n",
    "\n",
    "print(\"Number of filtered training examples:\", len(x_train))\n",
    "print(\"Number of filtered test examples:\", len(x_test))\n",
    "\n",
    "print(y_train[0])\n",
    "seaborn.heatmap(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fmmtplIFGL6t"
   },
   "source": [
    "But an image size of 28x28 is much too large for current quantum computers. Resize the image down to 4x4 and scale the numbers between 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lR4tKxLOGL6u"
   },
   "outputs": [],
   "source": [
    "def reduce_image(x):\n",
    "    x = tf.reshape(x, [1, 28, 28, 1])\n",
    "    x = tf.image.resize(x, [4, 4])\n",
    "    x = tf.reshape(x, [4, 4])\n",
    "    x = x / 255\n",
    "    return x.numpy()\n",
    "\n",
    "\n",
    "x_train = [reduce_image(x) for x in x_train]\n",
    "x_test = [reduce_image(x) for x in x_test]\n",
    "\n",
    "\n",
    "# Remove examples where the same input has multiple labels.\n",
    "def remove_contradicting(xs, ys):\n",
    "    mapping = collections.defaultdict(set)\n",
    "    for x, y in zip(xs, ys):\n",
    "        mapping[str(x)].add(y)\n",
    "    return zip(*((x, y) for x, y in zip(xs, ys) if len(mapping[str(x)]) == 1))\n",
    "\n",
    "\n",
    "x_train, y_train = remove_contradicting(x_train, y_train)\n",
    "x_test, y_test = remove_contradicting(x_test, y_test)\n",
    "\n",
    "print(\"Number of non-contradicting training examples: \", len(x_train))\n",
    "print(\"Number of non-contradicting test examples: \", len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pOMd7zIjGL6x"
   },
   "source": [
    "Again, display the first training exampleâ€”after resize: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YIYOtCRIGL6y"
   },
   "outputs": [],
   "source": [
    "print(y_train[0])\n",
    "seaborn.heatmap(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_3kBLeodGL61"
   },
   "source": [
    "To process images using a quantum computer, <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> proposed representing each pixel with a qubit, with the state depending on the value of the pixel.\n",
    "\n",
    "To classify these images, <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> proposed taking the expectation of a readout qubit in a parameterized circuit. The expectation returns a value between 1 and -1, so choosing 1 and -1 as the targets is natural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aOu_3-3ZGL61"
   },
   "outputs": [],
   "source": [
    "def convert_to_circuit(image):\n",
    "    \"\"\"Encode truncated classical image into quantum datapoint.\"\"\"\n",
    "    values = np.ndarray.flatten(image)\n",
    "    qubits = cirq.GridQubit.rect(4, 4)\n",
    "    circuit = cirq.Circuit()\n",
    "    for i, value in enumerate(values):\n",
    "        if value > 0.5:\n",
    "            circuit.append(cirq.X(qubits[i]))\n",
    "    return circuit\n",
    "\n",
    "\n",
    "x_train = [convert_to_circuit(x) for x in x_train]\n",
    "x_test = [convert_to_circuit(x) for x in x_test]\n",
    "\n",
    "\n",
    "def convert_label(y):\n",
    "    if y == 3:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return -1.0\n",
    "\n",
    "\n",
    "y_train = [convert_label(y) for y in y_train]\n",
    "y_test = [convert_label(y) for y in y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zkr6jVDgGL64"
   },
   "source": [
    "And display the circuit diagram for the first example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qP-wmm-0GL65"
   },
   "outputs": [],
   "source": [
    "print(y_train[0])\n",
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4USiqeOqGL67"
   },
   "source": [
    "## 2. Quantum neural network\n",
    "\n",
    "There is little guidance for a quantum circuit structure that classifies images. Since the classification is based on the expectation of the readout qubit, <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> propose using two qubit gates, with the readout qubit always acted upon.\n",
    "\n",
    "This following example shows this layer approach. It uses *n* instances of the same gate, with each of the data qubits acting on the readout qubit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JiALbpwRGL69"
   },
   "outputs": [],
   "source": [
    "def create_quantum_model():\n",
    "    \"\"\"Create a QNN model circuit and readout operation to go along with it.\"\"\"\n",
    "    data_qubits = cirq.GridQubit.rect(4, 4)\n",
    "    readout = cirq.GridQubit(16, 0)\n",
    "\n",
    "    symbols = []\n",
    "    circuit = cirq.Circuit()\n",
    "\n",
    "    # Generates a layer of the gate type.\n",
    "    def layer(gate, prefix):\n",
    "        for i, qubit in enumerate(data_qubits):\n",
    "            symbol = sympy.Symbol(prefix + '-' + str(i))\n",
    "            circuit.append(gate(qubit, readout)**symbol)\n",
    "            symbols.append(symbol)\n",
    "\n",
    "    # Prepare the readout qubit.\n",
    "    circuit.append(cirq.X(readout))\n",
    "    circuit.append(cirq.H(readout))\n",
    "\n",
    "    # Then add layers (experiment by adding more).\n",
    "    layer(cirq.XX, \"xx-1\")\n",
    "    layer(cirq.ZZ, \"zz-1\")\n",
    "\n",
    "    # Finally, prepare the readout qubit.\n",
    "    circuit.append(cirq.H(readout))\n",
    "\n",
    "    return circuit, cirq.Z(readout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LY7vbY6yfABE"
   },
   "source": [
    "Build the Keras model with the quantum components. This model is fed the \"quantum data\" that encodes the classical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x2xDsYpFGL7A"
   },
   "outputs": [],
   "source": [
    "# Get the quantum components.\n",
    "model_circuit, model_readout = create_quantum_model()\n",
    "\n",
    "# Build the Keras model.\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=(), dtype=tf.dtypes.string))\n",
    "model.add(tfq.layers.PQC(model_circuit, model_readout))\n",
    "\n",
    "\n",
    "# Define a custom accuracy that equals the sign of the output.\n",
    "@tf.function\n",
    "def custom_accuracy(y_true, y_pred):\n",
    "    y_true = tf.squeeze(y_true)\n",
    "    y_pred = tf.map_fn(lambda x: 1.0 if x >= 0 else -1.0, y_pred)\n",
    "    return tf.keras.backend.mean(tf.keras.backend.equal(y_true, y_pred))\n",
    "\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(loss=tf.keras.losses.hinge,\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=[custom_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lsuOzDYblA9s"
   },
   "source": [
    "Reduce the dataset size for faster training. For better results, ignore this code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n8vuQpSLlBV2"
   },
   "outputs": [],
   "source": [
    "# Comment out for increased accuracy.\n",
    "NUM_EXAMPLES = 500\n",
    "x_train = x_train[:NUM_EXAMPLES]\n",
    "y_train = y_train[:NUM_EXAMPLES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QMSdgGC1GL7D"
   },
   "source": [
    "Using the full dataset, training this model should achieve >85% accuracy on the test set. Here, only `NUM_EXAMPLES` datapoints are used to save time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nl0aQ-w7GL7H"
   },
   "outputs": [],
   "source": [
    "# Wrap the training and test sets so Keras can handle them.\n",
    "x_train = tfq.convert_to_tensor(x_train)\n",
    "x_test = tfq.convert_to_tensor(x_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=32,\n",
    "          epochs=3,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "qnn_results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8952YvuWGL7J"
   },
   "source": [
    "## 3. Classical neural network\n",
    "\n",
    "While the quantum neural network works for this simplified MNIST problem, a basic classical neural network can easily outperform a QNN on this task. After a single epoch, a classical neural network can achieve >98% accuracy on the holdout set.\n",
    "\n",
    "In the following example, a classical neural network is used for a 10-class classification problem (instead of the 2-class problem for the QNN), and uses the entire 28x28 image instead of subsampling the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pZofEHhLGL7L"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "\n",
    "def create_classical_model():\n",
    "    # A simple model based off LeNet from https://keras.io/examples/mnist_cnn/\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Reshape([28, 28, 1]))\n",
    "    model.add(tf.keras.layers.Conv2D(32, [3, 3], activation='relu'))\n",
    "    model.add(tf.keras.layers.Conv2D(64, [3, 3], activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.Dropout(0.25))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_classical_model()\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=128,\n",
    "          epochs=1,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "cnn_results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RH3mam7EGL7N"
   },
   "source": [
    "## 4. Comparison\n",
    "\n",
    "Despite a more difficult problem, the classical neural network easily outperforms the quantum neural network. For classical data, it is difficult to beat a classical neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NOMeN7pMGL7P"
   },
   "outputs": [],
   "source": [
    "qnn_accuracy = qnn_results[1]\n",
    "cnn_accuracy = cnn_results[1]\n",
    "\n",
    "seaborn.barplot([\"quantum\", \"classical\"], [qnn_accuracy, cnn_accuracy])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "mnist.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
